{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8aa031fb-7f6d-4d54-9acd-1ae25089fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72302a3a-5c70-4438-9d3e-1665058ffc01",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a543cfa2-3926-484a-aefc-01430e34c2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon | PROPN | proper noun\n",
      "flew | VERB | verb\n",
      "to | ADP | adposition\n",
      "mars | NOUN | noun\n",
      "yesterday | NOUN | noun\n",
      ". | PUNCT | punctuation\n",
      "He | PRON | pronoun\n",
      "carried | VERB | verb\n",
      "biryani | ADJ | adjective\n",
      "masala | NOUN | noun\n",
      "with | ADP | adposition\n",
      "him | PRON | pronoun\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Elon flew to mars yesterday. He carried biryani masala with him\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\"|\", token.pos_, \"|\", spacy.explain(token.pos_)) #part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d245e86-df36-4828-bbc1-5cfec355244f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names #the pipeline gives the pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7c5ac58-1174-43cf-8c27-b4de0c2af809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow | INTJ | interjection\n",
      "! | PUNCT | punctuation\n",
      "Dr. | PROPN | proper noun\n",
      "Strange | PROPN | proper noun\n",
      "made | VERB | verb\n",
      "265 | NUM | numeral\n",
      "million | NUM | numeral\n",
      "$ | NUM | numeral\n",
      "on | ADP | adposition\n",
      "the | DET | determiner\n",
      "very | ADV | adverb\n",
      "first | ADJ | adjective\n",
      "day | NOUN | noun\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Wow! Dr. Strange made 265 million $ on the very first day\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\"|\", token.pos_, \"|\", spacy.explain(token.pos_)) #part of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d17f7b0e-cc81-4556-ae53-e4c6b50db662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wow | UH | interjection\n",
      "! | . | punctuation mark, sentence closer\n",
      "Dr. | NNP | noun, proper singular\n",
      "Strange | NNP | noun, proper singular\n",
      "made | VBD | verb, past tense\n",
      "265 | CD | cardinal number\n",
      "million | CD | cardinal number\n",
      "$ | CD | cardinal number\n",
      "on | IN | conjunction, subordinating or preposition\n",
      "the | DT | determiner\n",
      "very | RB | adverb\n",
      "first | JJ | adjective (English), other noun-modifier (Chinese)\n",
      "day | NN | noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"|\", token.tag_, \"|\", spacy.explain(token.tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f217d242-426f-47f5-8b98-03304caf56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spacy is good with tenses as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6c6349eb-0b74-4c94-a90e-a9e2532e4f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quit | VBD | verb, past tense\n",
      "quits | VBZ | verb, 3rd person singular present\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"He quit the job\")\n",
    "doc1 = nlp(\"He quits the job\")\n",
    "print(doc[1].text, \"|\", doc[1].tag_, \"|\", spacy.explain(doc[1].tag_))\n",
    "print(doc1[1].text, \"|\", doc1[1].tag_, \"|\", spacy.explain(doc1[1].tag_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9782cf94-9c3f-4d9c-8dac-dd52e8a265ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He | PRON | None\n",
      "quit | VERB | None\n",
      "the | DET | None\n",
      "job | NOUN | None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suhee\\AppData\\Roaming\\Python\\Python313\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '95' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\suhee\\AppData\\Roaming\\Python\\Python313\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '100' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\suhee\\AppData\\Roaming\\Python\\Python313\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '90' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n",
      "C:\\Users\\suhee\\AppData\\Roaming\\Python\\Python313\\site-packages\\spacy\\glossary.py:20: UserWarning: [W118] Term '92' not found in glossary. It may however be explained in documentation for the corpora used to train the language. Please check `nlp.meta[\"sources\"]` for any relevant links.\n",
      "  warnings.warn(Warnings.W118.format(term=term))\n"
     ]
    }
   ],
   "source": [
    "#we can remove extra text(punc, etc, space) from a doc by:\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\"SPACE\", \"X\", \"PUNCT\"]:\n",
    "        print(token, \"|\", token.pos_, \"|\", spacy.explain(token.pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7199c22-79ac-4a02-b7fc-9d12fabaef83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{95: 1, 100: 1, 90: 1, 92: 1}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74e0f5f3-8a5d-4ef2-b765-6eb387a5cb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.vocab[100].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6a28f-7de3-4090-86ce-2153bdb25b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
